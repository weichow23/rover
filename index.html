<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    <title>ROVER</title>
    <link rel="icon" type="image/x-icon" href="./static/img/icons/logo.png">
    
    <!-- Meta Tags -->
    <meta property="og:url" content="https://vision-x-nyu.github.io/thinking-in-space.github.io/" />
    <meta property="og:image" content="./static/img/icons/logo.png" />
    <meta property="og:title" content="Thinking in Space: How Multimodal Large Language Models See, Remember and Recall Spaces" />
    
    <meta name="twitter:url" content="https://vision-x-nyu.github.io/thinking-in-space.github.io/" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Thinking in Space: How Multimodal Large Language Models See, Remember and Recall Spaces" />
    <meta name="twitter:description" content="We introduce VSI-Bench, a novel benchmark of over 5,000 video-based visual-spatial intelligence questions, to evaluate and probe MLLMs." />

    <!-- Preload critical resources -->
    <link rel="preload" href="./static/css/style.css" as="style">
    <link rel="preload" href="./static/img/icons/logo.png" as="image">
    <link rel="preconnect" href="https://polyfill.io">
    <link rel="preconnect" href="https://cdn.jsdelivr.net">
    <link rel="preconnect" href="https://d3js.org">

    <!-- Critical CSS inlined -->
    <style>
        /* Critical path CSS - Basic layout and above-the-fold content */
        body { margin: 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; }
        .header-wrapper { background: #fff; padding: 2rem 2rem; }
        .header-container { max-width: 1400px; margin: 0 auto; padding: 0 0; display: flex; align-items: center; }
        .header-content { flex: 1; }
        .header-image { flex: 0 0 auto; }
        .teaser-image { max-width: 400px; width: 100%; height: auto; }
        h1 { font-size: 3rem; margin: 0; color: #2d3748; }
        h2 { font-size: 1.5rem; margin: 0.5rem 0; color: #4a5568; }
        .button-container { display: flex; gap: 1rem; margin-top: 1rem; flex-wrap: wrap; }
        .button { display: inline-flex; align-items: center; gap: 0.5rem; padding: 0.75rem 1rem; background: #3182ce; color: white; text-decoration: none; border-radius: 0.375rem; transition: background-color 0.2s; }
        .button:hover { background: #7150cd; }
        /* Basic Styles */
        pre, code { font-size: 16px; }

        /* Author link styling */
        .author-block a {
            color: #363636;
            text-decoration: none;
            border-bottom: 1px solid transparent;
            transition: all 0.2s ease;
        }
        
        .author-block a:hover {
            color: var(--mgt-red);
            border-bottom-color: var(--mgt-red);
        }
        
        d-figure {
        display: block;
        width: 100%;
        text-align: center;
        margin: 20px 0;
        }

        d-figure figure {
        margin: 0 auto;
        display: inline-block;
        max-width: 100%;
        }

        d-figure img {
        display: block;
        margin: 0 auto;
        max-width: 100%;
        height: auto;
        }
        
        d-figure figcaption {
            text-align: justify;
            margin-top: 15px;
            padding: 0 20px;
            /* max-width: 1000px; */ /* Removed max-width constraint */
            margin-left: auto;
            margin-right: auto;
        }
        
        /* Leaderboard Styles */
        .leaderboard-table {
            width: 140%;
            margin-left: -20%;
            border-collapse: separate;
            border-spacing: 0;
            background: #ffffff;
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;
            font-size: 14px;
            margin-bottom: 40px;
        }

        .leaderboard-container { position: relative; }
        
        .leaderboard-table thead {
            background: #4a5568;
            color: white;
        }

        .leaderboard-table th {
            padding: 14px 12px;
            text-align: center;
            font-weight: 600;
            font-size: 13px;
            letter-spacing: 0.025em;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
            position: relative;
        }

        .sortable-header {
            cursor: pointer;
            user-select: none;
        }
        
        .sortable-header .sort-indicator {
            position: absolute;
            right: 8px;
            top: 50%;
            font-size: 14px;
            line-height: 1;
            transform: translateY(-50%);
            color: #a0aec0;
        }

        .sortable-header.active .sort-indicator { color: white; }
        
        .section-header {
            background-color: #deeef8;
            font-weight: 700;
            color: #2d3748;
            letter-spacing: 1px;
            font-size: 18px;
            text-align: center;
            padding: 12px !important;
            border-bottom: 2px solid #e2e8f0;
        }

        .leaderboard-table td {
            padding: 12px;
            border-bottom: 1px solid #e2e8f0;
            color: #4a5568;
            text-align: center;
        }
        
        .leaderboard-table tbody tr {
            transition: background-color 0.15s ease;
        }
        
        .leaderboard-table tbody tr:hover {
            background-color: #f7fafc;
        }

        .leaderboard-table td:first-child {
            font-weight: 600;
            text-align: left;
            color: #2d3748;
            padding-left: 20px;
        }
        
        .leaderboard-table td:nth-child(8) {
            font-weight: 700;
            font-size: 15px;
            color: #2d3748;
        }
        
        .human-level-row {
            background: #fffbeb85 !important;
            font-weight: 600;
        }
        
        .top-performer {
            background: #f0fdf494 !important;
        }

        .top-performer td:first-child::before {
            content: 'ü•á ';
        }

        .model-badge {
            display: inline-block;
            padding: 2px 6px;
            border-radius: 4px;
            font-size: 11px;
            font-weight: 500;
            margin-left: 8px;
            text-transform: uppercase;
            letter-spacing: 0.025em;
        }

        .proprietary-badge {
            background: #e2e8f0;
            color: #475569;
            border: 1px solid #cbd5e0;
        }
        .open-badge {
            background: #e6fffa;
            color: #047857;
            border: 1px solid #a7f3d0;
        }
        .edit-badge {
            background: #dbeafe;
            color: #1e40af;
            border: 1px solid #93c5fd;
        }

        .leaderboard-table tbody tr:nth-child(even) {
            background-color: #fafafa;
        }
        
        .baseline-row {
            font-style: italic;
            opacity: 0.8;
            background-color: #f9fafb;
        }
        
        .best-score {
            font-weight: 700;
            text-decoration: underline;
            text-decoration-color: #cbd5e0;
            text-underline-offset: 2px;
        }

        .section-divider {
            border-top: 2px solid #e2e8f0;
        }

        .highlight-box {
            background-color: #f0f9ff;
            border-left: 4px solid #3b82f6;
            padding: 16px;
            margin: 24px 0;
            border-radius: 4px;
        }

        .formula {
            text-align: center;
            margin: 20px 0;
            font-size: 18px;
        }

        .data-table {
            border-collapse: collapse;
            margin: 20px auto;
        }

        .data-table th,
        .data-table td {
            border: 1px solid #ddd;
            padding: 8px 12px;
            text-align: center;
        }

        .data-table thead {
            background-color: #f5f5f5;
        }
        
        /* ‰øÆÂ§çË°®Ê†ºÂÆπÂô®Â±Ö‰∏≠ */
        .table-comparison-container {
            display: flex;
            justify-content: center;
            align-items: flex-start;
            gap: 20px;
            margin: 20px 0;
        }
        
        .table-comparison-container table {
            margin: 0;
        }
        
        /* Mobile Responsive */
        @media (max-width: 768px) {
            .leaderboard-container {
                overflow-x: auto;
                -webkit-overflow-scrolling: touch;
                scroll-behavior: smooth;
                border-radius: 8px;
                box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
            }
            
            .leaderboard-table {
                width: 1200px;
                margin-left: 0;
                font-size: 12px;
                min-width: 1200px;
            }
            
            .leaderboard-table th,
            .leaderboard-table td {
                padding: 8px;
                white-space: nowrap;
                min-width: 80px;
            }
            
            .leaderboard-table td:first-child {
                min-width: 180px;
                max-width: 180px;
                overflow: hidden;
                text-overflow: ellipsis;
                padding-left: 12px;
            }

            .leaderboard-container::after {
                content: "‚Üê Swipe to scroll ‚Üí";
                position: absolute;
                bottom: -25px;
                left: 50%;
                transform: translateX(-50%);
                font-size: 11px;
                color: #666;
                font-style: italic;
                pointer-events: none;
            }
            
            .table-comparison-container {
                flex-direction: column;
                align-items: center;
            }
        }
    </style>

    <!-- Non-critical CSS loaded asynchronously -->
    <!-- Critical CSS files loaded synchronously -->
    <!-- All CSS loaded synchronously to prevent FOUC -->
    <link rel="stylesheet" href="./static/css/style.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

    <!-- KaTeX for Math -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">
</head>

<body>
    <!-- Header Section -->
    <div class="header-wrapper">
        <div class="header-container" id="header-container">
            <div class="header-content">
                <h1 style="margin-top: 0px">
                    <i><span class="rover-logo">
                        <span class="r1">R</span><span class="o">O</span><span class="v">V</span><span class="e">E</span><span class="r2">R</span>
                    </span></i>
                </h1>
                
                <h2>Benchmarking Reciprocal Cross-Modal Reasoning for Omnimodal Generation</h2>

                <div>
                    <!-- Paper authors -->
                    <span class="author-block">
                        <a href="" target="_blank">
                            Yongyuan Liang</a><sup style="font-size: 0.8em;">‚ñ≥*</sup>,</span>
                    <span class="author-block">
                        <a href="" target="_blank">
                            Wei Chow</a><sup style="font-size: 0.8em;">‚ñ≤*</sup>,</span>
                    <span class="author-block">
                        <a href="" target="_blank">Feng Li</a><sup style="font-size: 0.8em;">‚ô¶</sup>,</span>
                    <span class="author-block">
                        <a href="" target="_blank">Ziqiao Ma</a><sup style="font-size: 0.8em;">‚ô£</sup>,
                    </span>
                    <span class="author-block">
                        <a href="" target="_blank">Xiyao Wang</a><sup style="font-size: 0.8em;">‚ñ≥</sup>,
                    </span>
                    <span class="author-block">
                        <a href="" target="_blank">Jiageng Mao</a><sup style="font-size: 0.8em;">‚òÖ</sup>,
                    </span>
                    <br>
                    <span class="author-block">
                        <a href="" target="_blank">Jiuhai Chen</a><sup style="font-size: 0.8em;">‚ñ≥</sup>,
                    </span>
                    <span class="author-block">
                        <a href="" target="_blank">Jiatao Gu</a><sup style="font-size: 0.8em;">‚ñ≤</sup>,
                    </span>
                    <span class="author-block">
                        <a href="" target="_blank">Yue Wang</a><sup style="font-size: 0.8em;">‚òÖ</sup>,
                    </span>
                    <span class="author-block">
                        <a href="" target="_blank">Furong Huang</a><sup style="font-size: 0.8em;">‚ñ≥</sup>,
                    </span>
                </div>

                <div>
                    <span class="author-block"><sup style="font-size: 0.8em;">‚ñ≥</sup>University of Maryland, College Park,</span>
                    <span class="author-block"><sup style="font-size: 0.8em;">‚ñ≤</sup>University of Pennsylvania,</span>
                    <span class="author-block"><sup style="font-size: 0.8em;">‚òÖ</sup>University of Southern California,</span>
                    <br>
                    <span class="author-block"><sup style="font-size: 0.8em;">‚ô£</sup>University of Michigan</span>
                    <span class="author-block"><sup style="font-size: 0.8em;">‚ô¶</sup>The Hong Kong University of Science and
                        Technology</span>
                    <span class="eql-cntrb"><br><sup style="font-size: 0.8em;">*</sup>Equal contribution.</span>
                </div>

                <div class="button-container">
                    <a href="https://arxiv.org/abs/2412.14171" class="button paper-link" target="_blank">
                        <span class="icon is-small"><i class="ai ai-arxiv"></i></span>
                        arXiv (soon)
                    </a>
                    <a href="https://github.com/vision-x-nyu/thinking-in-space" class="button" target="_blank">
                        <span class="icon is-small"><i class="fab fa-github"></i></span>
                        <span>Code (soon)</span>
                    </a>                      
                    <a href="https://huggingface.co/datasets/nyu-visionx/VSI-Bench" class="button" target="_blank">
                        <span class="icon is-small">
                            <img src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" alt="Hugging Face logo" style="height: 1em;" loading="lazy">
                        </span>
                        <span>ROVER (soon)</span>
                    </a>
                    <a href="#rover-demo" class="button">
                        <span class="icon is-small">
                            <img src="./static/img/data_icon.png" alt="Leaderboard logo" style="height: 1em;" loading="lazy">
                        </span>
                        <span>Data Viewer</span>
                    </a>
                    <a href="#rover-leaderboard" class="button">
                        <span class="icon is-small">
                            <img src="./static/img/leaderboard-star-svgrepo-com.svg" alt="Leaderboard logo" style="height: 1em;" loading="lazy">
                        </span>
                        <span>Leaderboard</span>
                    </a>
                </div>   

            </div>
        </div>
    </div>

    <d-article>
        <!-- Teaser Figure -->
        <d-figure id="fig-teaser">
            <figure>
                <img data-zoomable="" draggable="false" src="static/img/teaser.png" alt="Visual-Spatial Intelligence Teaser" loading="lazy">
                <figcaption>
                    <strong>Figure 1:</strong> The <span class="rover-logo">
  <span class="r1">R</span><span class="o">O</span><span class="v">V</span><span class="e">E</span><span class="r2">R</span>
</span> benchmark. <span class="rover-logo">
  <span class="r1">R</span><span class="o">O</span><span class="v">V</span><span class="e">E</span><span class="r2">R</span>
</span> evaluates UMMs through reciprocal cross-modal reasoning: \ourvg (left) requires generating images with language-augmented reasoning, while \ourir (right) requires generating text answers with visually-augmented reasoning.
                </figcaption>
            </figure>
        </d-figure>

        <!-- Abstract -->
        <p class="text">
            Unified multimodal models (UMMs) have shown remarkable advances in understanding and generating text and images. However, prevailing evaluations treat these abilities in isolation, such that tasks with multimodal inputs and outputs are scored primarily through unimodal reasoning. Existing benchmarks rarely require the use of one modality to guide, verify, or refine outputs in the other, failing to capture a central aspiration of unified multimodal models: seamless reasoning across modalities. We address this gap with <span class="rover-logo">
  <span class="r1">R</span><span class="o">O</span><span class="v">V</span><span class="e">E</span><span class="r2">R</span>
</span>, a human-annotated benchmark that explicitly targets reciprocal cross-modal reasoning, containing over 1,200 tasks grounded in 2,048 images spanning two complementary settings.
        </p>

        <div class="icon-container">
            <div class="icon-item">
                <img src="./static/img/icons/bench.svg" alt="Benchmark Icon" loading="lazy">
                <div><strong>Reciprocal Reasoning</strong>: We introduce the first benchmark targeting reciprocal cross-modal reasoning where one modality guides, verifies, or refines outputs in another.</div>
            </div>
            <div class="icon-item">
                <img src="./static/img/icons/evaluation.svg" alt="Evaluation Icon" loading="lazy">
                <div><strong>Dual Settings</strong>: <span class="rover-logo">
  <span class="r1">R</span><span class="o">O</span><span class="v">V</span><span class="e">E</span><span class="r2">R</span>
</span> evaluates verbally-augmented visual generation and visually-augmented verbal reasoning across diverse domains and reasoning types.</div>
            </div>
            <div class="icon-item">
                <img src="./static/img/icons/speech.svg" alt="Generation Icon" class="icon" loading="lazy">
                <div><strong>Comprehensive Evaluation</strong>: Multi-dimensional evaluation protocol assessing reasoning process, output alignment, and cross-modal consistency.</div>
            </div>
            <div class="icon-item">
                <img src="./static/img/icons/vision.svg" alt="Analysis Icon" class="icon" loading="lazy">
                <div><strong>Key Insights</strong>: Cross-modal reasoning strongly correlates with visual generation performance, while current models show limited visually-augmented reasoning capabilities.</div>
            </div>
        </div>

        <!-- Navigation Icons -->
        <div class="icon-row">
            <a href="#rover-benchmark" class="icon-link">
                <img src="./static/img/icons/bench.svg" alt="Benchmark Logo" class="icon" loading="lazy">
                ROVER<br>Benchmark
            </a>
            <a href="#evaluation-protocol" class="icon-link">
                <img src="./static/img/icons/evaluation.svg" alt="Evaluation Logo" class="icon" loading="lazy">
                Evaluation<br>Protocol
            </a>
            <a href="#rover-leaderboard" class="icon-link">
                <img src="./static/img/leaderboard-star-svgrepo-com.svg" alt="Leaderboard Logo" class="icon" loading="lazy">
                ROVER<br>Leaderboard
            </a>
            <a href="#experimental-results" class="icon-link">
                <img src="./static/img/icons/speech.svg" alt="Results Logo" class="icon" loading="lazy">
                Main<br>Results
            </a>
            <a href="#analysis-insights" class="icon-link">
                <img src="./static/img/icons/vision.svg" alt="Analysis Logo" class="icon" loading="lazy">
                Analysis &<br>Insights
            </a>
        </div>

        <p class="click-hint2" style="width: 85%;">
            <img src="static/img/icons/click.gif" style="width: 1.5rem" loading="lazy">
            <strong>Click to jump to each section.</strong>
        </p>

        <hr>


    <!-- ROVER Demo Section -->
    <h1 class="text"><span class="rover-logo">
        <span class="r1">R</span><span class="o">O</span><span class="v">V</span><span class="e">E</span><span class="r2">R</span>
    </span> Demo</h1>
    <div id="rover-demo" class="rover-demo">

        <h3 class="main-title">Verbally-augmented Reasoning for Visual Generation</h3>

        <div class="category-nav">
            <button class="category-btn active" onclick="showCategory('natural-science')">Natural Science</button>
            <button class="category-btn" onclick="showCategory('culture-art')">Culture and Art</button>
            <button class="category-btn" onclick="showCategory('common-sense')">Common Sense</button>
            <button class="category-btn" onclick="showCategory('logic')">Logic</button>
        </div>
    
        <!-- Top Thumbnail Row -->
        <div class="top-thumbnails">
            <!-- Natural Science Thumbnails -->
            <div id="natural-science-thumbnails" class="thumbnail-row">
                <img class="top-thumbnail" src="./static/img/demo/science_1.jpg" alt="Natural Science 1" onclick="showDetail('natural-science', 'item1')">
                <img class="top-thumbnail" src="./static/img/demo/science_2.jpg" alt="Natural Science 2" onclick="showDetail('natural-science', 'item2')">
                <img class="top-thumbnail" src="./static/img/demo/science_3.jpg" alt="Natural Science 3" onclick="showDetail('natural-science', 'item3')">
                <img class="top-thumbnail" src="./static/img/demo/science_4.jpg" alt="Natural Science 4" onclick="showDetail('natural-science', 'item4')">
                <img class="top-thumbnail" src="./static/img/demo/science_5.jpg" alt="Natural Science 5" onclick="showDetail('natural-science', 'item5')">
                <img class="top-thumbnail" src="./static/img/demo/science_6.jpg" alt="Natural Science 6" onclick="showDetail('natural-science', 'item6')">
                <img class="top-thumbnail" src="./static/img/demo/science_7.jpg" alt="Natural Science 7" onclick="showDetail('natural-science', 'item7')">
                <img class="top-thumbnail" src="./static/img/demo/science_8.jpg" alt="Natural Science 8" onclick="showDetail('natural-science', 'item8')">
                <img class="top-thumbnail" src="./static/img/demo/science_9.jpg" alt="Natural Science 9" onclick="showDetail('natural-science', 'item9')">
                <img class="top-thumbnail" src="./static/img/demo/science_10.jpg" alt="Natural Science 10" onclick="showDetail('natural-science', 'item10')">
                <img class="top-thumbnail" src="./static/img/demo/science_11.jpg" alt="Natural Science 11" onclick="showDetail('natural-science', 'item11')">
                <img class="top-thumbnail" src="./static/img/demo/science_12.jpg" alt="Natural Science 12" onclick="showDetail('natural-science', 'item12')">
            </div>
    
            <!-- Culture and Art Thumbnails -->
            <div id="culture-art-thumbnails" class="thumbnail-row" style="display: none;">
                <img class="top-thumbnail" src="./static/img/demo/culture_1.jpg" alt="Culture 1" onclick="showDetail('culture-art', 'item1')">
                <img class="top-thumbnail" src="./static/img/demo/culture_2.jpg" alt="Culture 2" onclick="showDetail('culture-art', 'item2')">
                <img class="top-thumbnail" src="./static/img/demo/culture_3.jpg" alt="Culture 3" onclick="showDetail('culture-art', 'item3')">
                <img class="top-thumbnail" src="./static/img/demo/culture_4.jpg" alt="Culture 4" onclick="showDetail('culture-art', 'item4')">
                <img class="top-thumbnail" src="./static/img/demo/culture_5.jpg" alt="Culture 5" onclick="showDetail('culture-art', 'item5')">
                <img class="top-thumbnail" src="./static/img/demo/culture_6.jpg" alt="Culture 6" onclick="showDetail('culture-art', 'item6')">
                <img class="top-thumbnail" src="./static/img/demo/culture_7.jpg" alt="Culture 7" onclick="showDetail('culture-art', 'item7')">
                <img class="top-thumbnail" src="./static/img/demo/culture_8.jpg" alt="Culture 8" onclick="showDetail('culture-art', 'item8')">
                <img class="top-thumbnail" src="./static/img/demo/culture_9.jpg" alt="Culture 9" onclick="showDetail('culture-art', 'item9')">
                <img class="top-thumbnail" src="./static/img/demo/culture_10.jpg" alt="Culture 10" onclick="showDetail('culture-art', 'item10')">
                <img class="top-thumbnail" src="./static/img/demo/culture_11.jpg" alt="Culture 11" onclick="showDetail('culture-art', 'item11')">
                <img class="top-thumbnail" src="./static/img/demo/culture_12.jpg" alt="Culture 12" onclick="showDetail('culture-art', 'item12')">
            </div>
    
            <!-- Common Sense Thumbnails -->
            <div id="common-sense-thumbnails" class="thumbnail-row" style="display: none;">
                <img class="top-thumbnail" src="./static/img/demo/common_1.jpg" alt="Common Sense 1" onclick="showDetail('common-sense', 'item1')">
                <img class="top-thumbnail" src="./static/img/demo/common_2.jpg" alt="Common Sense 2" onclick="showDetail('common-sense', 'item2')">
                <img class="top-thumbnail" src="./static/img/demo/common_3.jpg" alt="Common Sense 3" onclick="showDetail('common-sense', 'item3')">
                <img class="top-thumbnail" src="./static/img/demo/common_4.jpg" alt="Common Sense 4" onclick="showDetail('common-sense', 'item4')">
                <img class="top-thumbnail" src="./static/img/demo/common_5.jpg" alt="Common Sense 5" onclick="showDetail('common-sense', 'item5')">
                <img class="top-thumbnail" src="./static/img/demo/common_6.jpg" alt="Common Sense 6" onclick="showDetail('common-sense', 'item6')">
                <img class="top-thumbnail" src="./static/img/demo/common_7.jpg" alt="Common Sense 7" onclick="showDetail('common-sense', 'item7')">
                <img class="top-thumbnail" src="./static/img/demo/common_8.jpg" alt="Common Sense 8" onclick="showDetail('common-sense', 'item8')">
                <img class="top-thumbnail" src="./static/img/demo/common_9.jpg" alt="Common Sense 9" onclick="showDetail('common-sense', 'item9')">
                <img class="top-thumbnail" src="./static/img/demo/common_10.jpg" alt="Common Sense 10" onclick="showDetail('common-sense', 'item10')">
            </div>
    
            <!-- Logic Thumbnails -->
            <div id="logic-thumbnails" class="thumbnail-row" style="display: none;">
                <img class="top-thumbnail" src="./static/img/demo/logic_1.jpg" alt="Logic 1" onclick="showDetail('logic', 'item1')">
                <img class="top-thumbnail" src="./static/img/demo/logic_2.jpg" alt="Logic 2" onclick="showDetail('logic', 'item2')">
                <img class="top-thumbnail" src="./static/img/demo/logic_3.jpg" alt="Logic 3" onclick="showDetail('logic', 'item3')">
                <img class="top-thumbnail" src="./static/img/demo/logic_4.jpg" alt="Logic 4" onclick="showDetail('logic', 'item4')">
                <img class="top-thumbnail" src="./static/img/demo/logic_5.jpg" alt="Logic 5" onclick="showDetail('logic', 'item5')">
                <img class="top-thumbnail" src="./static/img/demo/logic_6.jpg" alt="Logic 6" onclick="showDetail('logic', 'item6')">
                <img class="top-thumbnail" src="./static/img/demo/logic_7.jpg" alt="Logic 7" onclick="showDetail('logic', 'item7')">
                <img class="top-thumbnail" src="./static/img/demo/logic_8.jpg" alt="Logic 8" onclick="showDetail('logic', 'item8')">
                <img class="top-thumbnail" src="./static/img/demo/logic_9.jpg" alt="Logic 9" onclick="showDetail('logic', 'item9')">
                <img class="top-thumbnail" src="./static/img/demo/logic_10.jpg" alt="Logic 10" onclick="showDetail('logic', 'item10')">
            </div>
        </div>
    
        <!-- Detail View - Always Visible -->
        <div id="detail-view" class="detail-container">
            <div class="detail-content">
                <div class="left-panel">
                    <div class="data-chart" id="data-chart">
                        Original Data Chart Placeholder
                    </div>
                    
                    <div class="prompt-section">
                        <h3>Prompt:</h3>
                        <div class="prompt-text" id="prompt-text">
                            Generate a detailed scientific diagram showing the molecular structure of water, including accurate bond angles and electron cloud representations. Use clear labels and a clean, academic style suitable for a chemistry textbook.
                        </div>
                    </div>
                </div>
    
                <div class="right-panel">
                    <div class="model-result">
                        <div class="model-name nano">Nano Banana</div>
                        <div class="generated-image" id="nano-result">
                            Generated Image Placeholder
                        </div>
                    </div>
    
                    <div class="model-result">
                        <div class="model-name gpt">GPT-5</div>
                        <div class="generated-image" id="gpt-result">
                            Generated Image Placeholder
                        </div>
                    </div>
    
                    <div class="model-result">
                        <div class="model-name bagel">BAGEL-Think</div>
                        <div class="generated-image" id="bagel-result">
                            Generated Image Placeholder
                        </div>
                    </div>
    
                    <div class="model-result">
                        <div class="model-name qwen">Qwen-Image</div>
                        <div class="generated-image" id="qwen-result">
                            Generated Image Placeholder
                        </div>
                    </div>
                </div>
            </div>
        </div>
    
        <script>
            let currentCategory = 'natural-science';
            
            // Sample data for different categories and items
            const sampleData = {
                'natural-science': {
                    'item1': {
                        chart: './static/img/demo/science_1.jpg',
                        reasoning_type: 'Temporal',
                        prompt: 'What this methylene blue and titanium dioxide solution will look like after 30 minutes under UV light exposure.',
                        nano: './static/img/nano/science_1.png',
                        gpt: './static/img/gpt/science_1.png',
                        bagel: './static/img/bagel/science_1.png',
                        qwen: './static/img/qwen/science_1.png'
                    },
                    'item2': {
                        chart: './static/img/demo/science_2.jpg',
                        reasoning_type: 'Temporal',
                        prompt: 'What will these iron nails look like after soaking in 3% saltwater for 4 hours?',
                        nano: './static/img/nano/science_2.png',
                        gpt: './static/img/gpt/science_2.png',
                        bagel: './static/img/bagel/science_2.png',
                        qwen: './static/img/qwen/science_2.png'
                    },
                    'item3': {
                        chart: './static/img/demo/science_3.jpg',
                        reasoning_type: 'Temporal',
                        prompt: 'Show what these two candles will look like after 2 hours, with the left candle in normal air and the right candle partially enclosed to restrict airflow.',
                        nano: './static/img/nano/science_3.png',
                        gpt: './static/img/gpt/science_3.png',
                        bagel: './static/img/bagel/science_3.png',
                        qwen: './static/img/qwen/science_3.png'
                    },
                    'item4': {
                        chart: './static/img/demo/science_4.jpg',
                        reasoning_type: 'Spatial',
                        prompt: 'Generate what happens when a beam of white light passes through this triangular glass prism.',
                        nano: './static/img/nano/science_4.png',
                        gpt: './static/img/gpt/science_4.png',
                        bagel: './static/img/bagel/science_4.png',
                        qwen: './static/img/qwen/science_4.png'
                    },
                    'item5': {
                        chart: './static/img/demo/science_5.jpg',
                        reasoning_type: 'Spatial',
                        prompt: 'Predict the visual effect when this glass is replaced with a concave lens of the same size.',
                        nano: './static/img/nano/science_5.png',
                        gpt: './static/img/gpt/science_5.png',
                        bagel: './static/img/bagel/science_5.png',
                        qwen: './static/img/qwen/science_5.png'
                    },
                    'item6': {
                        chart: './static/img/demo/science_6.jpg',
                        reasoning_type: 'Causal',
                        prompt: 'Predict what happens when one wooden block is removed from the third layer (counting from bottom) of this tower.',
                        nano: './static/img/nano/science_6.png',
                        gpt: './static/img/gpt/science_6.png',
                        bagel: './static/img/bagel/science_6.png',
                        qwen: './static/img/qwen/science_6.png'
                    },
                    'item7': {
                        chart: './static/img/demo/science_7.jpg',
                        reasoning_type: 'Causal',
                        prompt: 'Predict how this leaf cross-section would look after the leaf has undergone severe drought stress that causes plasmolysis in the mesophyll cells.',
                        nano: './static/img/nano/science_7.png',
                        gpt: './static/img/gpt/science_7.png',
                        bagel: './static/img/bagel/science_7.png',
                        qwen: './static/img/qwen/science_7.png'
                    },
                    'item8': {
                        chart: './static/img/demo/science_8.jpg',
                        reasoning_type: 'Causal',
                        prompt: 'Predict what the plastic water bottle will look like after being left half-full, capped tightly, and placed in a freezer overnight.',
                        nano: './static/img/nano/science_8.png',
                        gpt: './static/img/gpt/science_8.png',
                        bagel: './static/img/bagel/science_8.png',
                        qwen: './static/img/qwen/science_8.png'
                    },
                    'item9': {
                        chart: './static/img/demo/science_9.jpg',
                        reasoning_type: 'Synthetic',
                        prompt: 'What this preserved microscopic specimen would look like as a living organism in its natural environment.',
                        nano: './static/img/nano/science_9.png',
                        gpt: './static/img/gpt/science_9.png',
                        bagel: './static/img/bagel/science_9.png',
                        qwen: './static/img/qwen/science_9.png'
                    },  
                    'item10': {
                        chart: './static/img/demo/science_10.jpg',
                        reasoning_type: 'Quantitative',
                        prompt: 'Generate this garden scene with yellow flowers increased to match the number of red flowers.',
                        nano: './static/img/nano/science_10.png',
                        gpt: './static/img/gpt/science_10.png',
                        bagel: './static/img/bagel/science_10.png',
                        qwen: './static/img/qwen/science_10.png'
                    },
                    'item11': {
                        chart: './static/img/demo/science_11.jpg',
                        reasoning_type: 'Synthetic',
                        prompt: 'Generate what this pressed botanical specimen would look like as a living plant in its natural state.',
                        nano: './static/img/nano/science_11.png',
                        gpt: './static/img/gpt/science_11.png',
                        bagel: './static/img/bagel/science_11.png',
                        qwen: './static/img/qwen/science_11.png'
                    },
                    'item12': {
                        chart: './static/img/demo/science_12.jpg',
                        reasoning_type: 'Quantitative',
                        prompt: 'Generate this scene with 3 total insects of the same type feeding on different flowers.',
                        nano: './static/img/nano/science_12.png',
                        gpt: './static/img/gpt/science_12.png',
                        bagel: './static/img/bagel/science_12.png',
                        qwen: './static/img/qwen/science_12.png'
                    }
                },
                'culture-art': {
                    'item1': {
                        chart: './static/img/demo/culture_1.jpg',
                        reasoning_type: 'Temporal',
                        prompt: 'Show this floral arrangement after the flowers have wilted and faded in oil painting style.',
                        nano: './static/img/nano/culture_1.png',
                        gpt: './static/img/gpt/culture_1.png',
                        bagel: './static/img/bagel/culture_1.png',
                        qwen: './static/img/qwen/culture_1.png'
                    },
                    'item2': {
                        chart: './static/img/demo/culture_2.jpg',
                        reasoning_type: 'Temporal',
                        prompt: 'Show this woman as she would appear 30 years later while maintaining the portrait style and setting.',
                        nano: './static/img/nano/culture_2.png',
                        gpt: './static/img/gpt/culture_2.png',
                        bagel: './static/img/bagel/culture_2.png',
                        qwen: './static/img/qwen/culture_2.png'
                    },
                    'item3': {
                        chart: './static/img/demo/culture_3.jpg',
                        reasoning_type: 'Spatial',
                        prompt: 'Show the front entrance view of the tower building on the right while preserving the winter painting style',
                        nano: './static/img/nano/culture_3.png',
                        gpt: './static/img/gpt/culture_3.png',
                        bagel: './static/img/bagel/culture_3.png',
                        qwen: './static/img/qwen/culture_3.png'
                    },
                    'item4': {
                        chart: './static/img/demo/culture_4.jpg',
                        reasoning_type: 'Spatial',
                        prompt: 'From the viewpoint of a person seated in a small wooden barge directly beneath the central arch of the bridge, generate the water-level scene looking outward.',
                        nano: './static/img/nano/culture_4.png',
                        gpt: './static/img/gpt/culture_4.png',
                        bagel: './static/img/bagel/culture_4.png',
                        qwen: './static/img/qwen/culture_4.png'
                    },
                    'item5': {
                        chart: './static/img/demo/culture_5.jpg',
                        reasoning_type: 'Causal',
                        prompt: 'Generate the scene showing these figures preparing to depart after their rest.',
                        nano: './static/img/nano/culture_5.png',
                        gpt: './static/img/gpt/culture_5.png',
                        bagel: './static/img/bagel/culture_5.png',
                        qwen: './static/img/qwen/culture_5.png'
                    },
                    'item6': {
                        chart: './static/img/demo/culture_6.jpg',
                        reasoning_type: 'Causal',
                        prompt: 'Show these grinding tools being used for their intended purpose.',
                        nano: './static/img/nano/culture_6.png',
                        gpt: './static/img/gpt/culture_6.png',
                        bagel: './static/img/bagel/culture_6.png',
                        qwen: './static/img/qwen/culture_6.png'
                    },
                    'item7': {
                        chart: './static/img/demo/culture_7.jpg',
                        reasoning_type: 'Synthetic',
                        prompt: 'Show this elegant woman in an outdoor social setting while preserving the classical painting style.',
                        nano: './static/img/nano/culture_7.png',
                        gpt: './static/img/gpt/culture_7.png',
                        bagel: './static/img/bagel/culture_7.png',
                        qwen: './static/img/qwen/culture_7.png'
                    },
                    'item8': {
                        chart: './static/img/demo/culture_8.jpg',
                        reasoning_type: 'Synthetic',
                        prompt: 'Combine all four classical figures into a single unified composition.',
                        nano: './static/img/nano/culture_8.png',
                        gpt: './static/img/gpt/culture_8.png',
                        bagel: './static/img/bagel/culture_8.png',
                        qwen: './static/img/qwen/culture_8.png'
                    },
                    'item9': {
                        chart: './static/img/demo/culture_9.jpg',
                        reasoning_type: 'Synthetic',
                        prompt: 'Re-imagine this Japanese ikebana arrangement as it would appear in a 17th-century Dutch Golden Age still-life painting.',
                        nano: './static/img/nano/culture_9.png',
                        gpt: './static/img/gpt/culture_9.png',
                        bagel: './static/img/bagel/culture_9.png',
                        qwen: './static/img/qwen/culture_9.png'
                    },
                    'item10': {
                        chart: './static/img/demo/culture_10.jpg',
                        reasoning_type: 'Synthetic',
                        prompt: 'Re-imagine this Impressionist riverside landscape as an Edo-period Japanese ukiyo-e woodblock print.',
                        nano: './static/img/nano/culture_10.png',
                        gpt: './static/img/gpt/culture_10.png',
                        bagel: './static/img/bagel/culture_10.png',
                        qwen: './static/img/qwen/culture_10.png'
                    },
                    'item11': {
                        chart: './static/img/demo/culture_11.jpg',
                        reasoning_type: 'Quantitative',
                        prompt: 'Generate this portrait with fruit quantity increased to the next prime number.',
                        nano: './static/img/nano/culture_11.png',
                        gpt: './static/img/gpt/culture_11.png',
                        bagel: './static/img/bagel/culture_11.png',
                        qwen: './static/img/qwen/culture_11.png'
                    },
                    'item12': {
                        chart: './static/img/demo/culture_12.jpg',
                        reasoning_type: 'Quantitative',
                        prompt: 'Generate this 19th-century still-life floral painting with a prime number of visible blossoms‚Äîwhile preserving the same dark background, earthenware jug, muted palette, and impressionist brushwork.',
                        nano: './static/img/nano/culture_12.png',
                        gpt: './static/img/gpt/culture_12.png',
                        bagel: './static/img/bagel/culture_12.png',
                        qwen: './static/img/qwen/culture_12.png'
                    }
                },
                'common-sense': {
                    'item1': {
                        chart: './static/img/demo/common_1.png',
                        prompt: 'Illustrate the proper way to pack a suitcase for a week-long trip, showing efficient use of space and organization of different types of clothing and accessories.',
                        nano: './static/img/nano/nano_common_1.png',
                        gpt: './static/img/gpt/gpt_common_1.png',
                        bagel: './static/img/bagel/bagel_common_1.png',
                        qwen: './static/img/qwen/qwen_common_1.png'
                    },
                    'item2': {
                        chart: './static/img/demo/common_2.png',
                        prompt: 'Show the step-by-step process of safely crossing a busy street, including looking both ways, using crosswalks, and timing with traffic signals.',
                        nano: './static/img/nano/nano_common_2.png',
                        gpt: './static/img/gpt/gpt_common_2.png',
                        bagel: './static/img/bagel/bagel_common_2.png',
                        qwen: './static/img/qwen/qwen_common_2.png'
                    },
                    'item3': {
                        chart: './static/img/demo/common_3.png',
                        prompt: 'Show the step-by-step process of safely crossing a busy street, including looking both ways, using crosswalks, and timing with traffic signals.',
                        nano: './static/img/nano/nano_common_3.png',
                        gpt: './static/img/gpt/gpt_common_3.png',
                        bagel: './static/img/bagel/bagel_common_3.png',
                        qwen: './static/img/qwen/qwen_common_3.png'
                    },
                    'item4': {
                        chart: './static/img/demo/common_4.png',
                        prompt: 'Show the step-by-step process of safely crossing a busy street, including looking both ways, using crosswalks, and timing with traffic signals.',
                        nano: './static/img/nano/nano_common_4.png',
                        gpt: './static/img/gpt/gpt_common_4.png',
                        bagel: './static/img/bagel/bagel_common_4.png',
                        qwen: './static/img/qwen/qwen_common_4.png'
                    },
                    'item5': {
                        chart: './static/img/demo/common_5.png',
                        prompt: 'Show the step-by-step process of safely crossing a busy street, including looking both ways, using crosswalks, and timing with traffic signals.',
                        nano: './static/img/nano/nano_common_5.png',
                        gpt: './static/img/gpt/gpt_common_5.png',
                        bagel: './static/img/bagel/bagel_common_5.png',
                        qwen: './static/img/qwen/qwen_common_5.png'
                    },
                    'item6': {
                        chart: './static/img/demo/common_6.png',
                        prompt: 'Show the step-by-step process of safely crossing a busy street, including looking both ways, using crosswalks, and timing with traffic signals.',
                        nano: './static/img/nano/nano_common_6.png',
                        gpt: './static/img/gpt/gpt_common_6.png',
                        bagel: './static/img/bagel/bagel_common_6.png',
                        qwen: './static/img/qwen/qwen_common_6.png'
                    },
                    'item7': {
                        chart: './static/img/demo/common_7.png',
                        prompt: 'Show the step-by-step process of safely crossing a busy street, including looking both ways, using crosswalks, and timing with traffic signals.',
                        nano: './static/img/nano/nano_common_7.png',
                        gpt: './static/img/gpt/gpt_common_7.png',
                        bagel: './static/img/bagel/bagel_common_7.png',
                        qwen: './static/img/qwen/qwen_common_7.png'
                    },
                    'item8': {
                        chart: './static/img/demo/common_8.png',
                        prompt: 'Show the step-by-step process of safely crossing a busy street, including looking both ways, using crosswalks, and timing with traffic signals.',
                        nano: './static/img/nano/nano_common_8.png',
                        gpt: './static/img/gpt/gpt_common_8.png',
                        bagel: './static/img/bagel/bagel_common_8.png',
                        qwen: './static/img/qwen/qwen_common_8.png'
                    },
                    'item9': {
                        chart: './static/img/demo/common_9.png',
                        prompt: 'Show the step-by-step process of safely crossing a busy street, including looking both ways, using crosswalks, and timing with traffic signals.',
                        nano: './static/img/nano/nano_common_9.png',
                        gpt: './static/img/gpt/gpt_common_9.png',
                        bagel: './static/img/bagel/bagel_common_9.png',
                        qwen: './static/img/qwen/qwen_common_9.png'
                    },
                    'item10': {
                        chart: './static/img/demo/common_10.png',
                        prompt: 'Show the step-by-step process of safely crossing a busy street, including looking both ways, using crosswalks, and timing with traffic signals.',
                        nano: './static/img/nano/nano_common_10.png',
                        gpt: './static/img/gpt/gpt_common_10.png',
                        bagel: './static/img/bagel/bagel_common_10.png',
                        qwen: './static/img/qwen/qwen_common_10.png'
                    }
                },
                'logic': {
                    'item1': {
                        chart: './static/img/demo/logic_1.png',
                        prompt: 'Create a visual representation of a logical syllogism: "All birds can fly. Penguins are birds. Therefore, penguins can fly." Show why this conclusion is flawed using diagrams and counter-examples.',
                        nano: './static/img/nano/nano_logic_1.png',
                        gpt: './static/img/gpt/gpt_logic_1.png',
                        bagel: './static/img/bagel/bagel_logic_1.png',
                        qwen: './static/img/qwen/qwen_logic_1.png'
                    },
                    'item2': {
                        chart: './static/img/demo/logic_2.png',
                        prompt: 'Illustrate the concept of logical fallacies using visual examples, specifically showing "correlation vs causation" with clear graphs and explanatory text.',
                        nano: './static/img/nano/nano_lo    gic_2.png',
                        gpt: './static/img/gpt/gpt_logic_2.png',
                        bagel: './static/img/bagel/bagel_logic_2.png',
                        qwen: './static/img/qwen/qwen_logic_2.png'
                    },
                    'item3': {
                        chart: './static/img/demo/logic_3.png',
                        prompt: 'Illustrate the concept of logical fallacies using visual examples, specifically showing "correlation vs causation" with clear graphs and explanatory text.',
                        nano: './static/img/nano/nano_logic_3.png',
                        gpt: './static/img/gpt/gpt_logic_3.png',
                        bagel: './static/img/bagel/bagel_logic_3.png',
                        qwen: './static/img/qwen/qwen_logic_3.png'
                    },
                    'item4': {
                        chart: './static/img/demo/logic_4.png',
                        prompt: 'Illustrate the concept of logical fallacies using visual examples, specifically showing "correlation vs causation" with clear graphs and explanatory text.',
                        nano: './static/img/nano/nano_logic_4.png',
                        gpt: './static/img/gpt/gpt_logic_4.png',
                        bagel: './static/img/bagel/bagel_logic_4.png',
                        qwen: './static/img/qwen/qwen_logic_4.png'
                    },
                    'item5': {
                        chart: './static/img/demo/logic_5.png',
                        prompt: 'Illustrate the concept of logical fallacies using visual examples, specifically showing "correlation vs causation" with clear graphs and explanatory text.',
                        nano: './static/img/nano/nano_logic_5.png',
                        gpt: './static/img/gpt/gpt_logic_5.png',
                        bagel: './static/img/bagel/bagel_logic_5.png',
                        qwen: './static/img/qwen/qwen_logic_5.png'
                    },
                    'item6': {
                        chart: './static/img/demo/logic_6.png',
                        prompt: 'Illustrate the concept of logical fallacies using visual examples, specifically showing "correlation vs causation" with clear graphs and explanatory text.',
                        nano: './static/img/nano/nano_logic_6.png',
                        gpt: './static/img/gpt/gpt_logic_6.png',
                        bagel: './static/img/bagel/bagel_logic_6.png',
                        qwen: './static/img/qwen/qwen_logic_6.png'
                    },
                    'item7': {
                        chart: './static/img/demo/logic_7.png',
                        prompt: 'Illustrate the concept of logical fallacies using visual examples, specifically showing "correlation vs causation" with clear graphs and explanatory text.',
                        nano: './static/img/nano/nano_logic_7.png',
                        gpt: './static/img/gpt/gpt_logic_7.png',
                        bagel: './static/img/bagel/bagel_logic_7.png',
                        qwen: './static/img/qwen/qwen_logic_7.png'
                    },
                    'item8': {
                        chart: './static/img/demo/logic_8.png',
                        prompt: 'Illustrate the concept of logical fallacies using visual examples, specifically showing "correlation vs causation" with clear graphs and explanatory text.',
                        nano: './static/img/nano/nano_logic_8.png',
                        gpt: './static/img/gpt/gpt_logic_8.png',
                        bagel: './static/img/bagel/bagel_logic_8.png',
                        qwen: './static/img/qwen/qwen_logic_8.png'
                    },
                    'item9': {
                        chart: './static/img/demo/logic_9.png',
                        prompt: 'Illustrate the concept of logical fallacies using visual examples, specifically showing "correlation vs causation" with clear graphs and explanatory text.',
                        nano: './static/img/nano/nano_logic_9.png',
                        gpt: './static/img/gpt/gpt_logic_9.png',
                        bagel: './static/img/bagel/bagel_logic_9.png',
                        qwen: './static/img/qwen/qwen_logic_9.png'
                    },
                    'item10': {
                        chart: './static/img/demo/logic_10.png',
                        prompt: 'Illustrate the concept of logical fallacies using visual examples, specifically showing "correlation vs causation" with clear graphs and explanatory text.',
                        nano: './static/img/nano/nano_logic_10.png',
                        gpt: './static/img/gpt/gpt_logic_10.png',
                        bagel: './static/img/bagel/bagel_logic_10.png',
                        qwen: './static/img/qwen/qwen_logic_10.png'
                    }
                }
            };
    
            function showCategory(category) {
    // Hide all thumbnail rows
                document.querySelectorAll('.thumbnail-row').forEach(container => {
                    container.style.display = 'none';
                });
                
                // Show selected category
                document.getElementById(category + '-thumbnails').style.display = 'flex';
                
                // Update active button
                document.querySelectorAll('.category-btn').forEach(btn => {
                    btn.classList.remove('active');
                });
                event.target.classList.add('active');
                
                currentCategory = category;
                
                // Load first item of the category by default
                showDetail(category, 'item1');
            }

                function showDetail(category, item) {
                // Update content based on selected item
                const data = sampleData[category] && sampleData[category][item];
                if (data) {
                    document.getElementById('data-chart').innerHTML = `
                        <img src="${data.chart}" alt="Data Chart" style="max-width: 100%; max-height: 100%; object-fit: contain;">
                        <div class="reasoning-type-label">${data.reasoning_type || 'Temporal'}</div>
                    `;
                    document.getElementById('prompt-text').textContent = data.prompt;
                    document.getElementById('nano-result').innerHTML = `<img src="${data.nano}" alt="Nano Banana Result" style="max-width: 100%; max-height: 100%; object-fit: contain;">`;
                    document.getElementById('gpt-result').innerHTML = `<img src="${data.gpt}" alt="GPT Result" style="max-width: 100%; max-height: 100%; object-fit: contain;">`;
                    document.getElementById('bagel-result').innerHTML = `<img src="${data.bagel}" alt="BAGEL-Think Result" style="max-width: 100%; max-height: 100%; object-fit: contain;">`;
                    document.getElementById('qwen-result').innerHTML = `<img src="${data.qwen}" alt="Qwen-Image Result" style="max-width: 100%; max-height: 100%; object-fit: contain;">`;
                }
            }
    
            function backToThumbnails() {
                document.getElementById('detail-view').style.display = 'none';
                document.getElementById(currentCategory + '-thumbnails').style.display = 'grid';
            }
            showDetail('natural-science', 'item1');
        </script>
    </div>


        <!-- ROVER Benchmark Section -->
        <div id='rover-benchmark' class="rover-benchmark">
            <div id="sec:rover-overview" class="sub-section">
                <h1 class="text"><span class="rover-logo">
  <span class="r1">R</span><span class="o">O</span><span class="v">V</span><span class="e">E</span><span class="r2">R</span>
</span> Benchmark</h1>
                <p class="text" align="justify">
                    <strong>Benchmark Overview:</strong> <span class="rover-logo">
  <span class="r1">R</span><span class="o">O</span><span class="v">V</span><span class="e">E</span><span class="r2">R</span>
</span> introduces the first benchmark specifically designed to evaluate reciprocal cross-modal reasoning in unified multimodal models. Unlike existing benchmarks that evaluate modalities in isolation, <span class="rover-logo">
  <span class="r1">R</span><span class="o">O</span><span class="v">V</span><span class="e">E</span><span class="r2">R</span>
</span> requires models to use information from one modality to inform and improve outputs in another. The benchmark comprises over 1,200 tasks grounded in about 2,048 images, targeting two complementary settings that capture the essence of cross-modal reasoning capabilities.
                </p>
                
                <d-figure id="fig-verbally-augmented">
                    <figure>
                        <img data-zoomable="" draggable="false" src="static/img/data.png" alt="Verbally-Augmented Reasoning" loading="lazy">
                        <figcaption style="text-align: center; margin-top: 20px;">
                            <strong>Figure 2: Verbally-Augmented Reasoning for Visual Generation.</strong> 
                            The benchmark spans 4 domains (natural science, culture and art, common sense, and logic), instantiated across 7 reasoning subtasks.
                        </figcaption>
                    </figure>
                </d-figure>
                
                <d-figure id="fig-visually-augmented">
                    <figure>
                        <img data-zoomable="" draggable="false" src="static/img/data_gtr.png" alt="Visually-Augmented Reasoning" loading="lazy">
                        <figcaption style="text-align: center; margin-top: 20px;">
                            <strong>Figure 3: Visually-Augmented Reasoning for Verbal Generation.</strong> 
                            The benchmark spans 3 scenarios and 6 subtasks: physical world modeling, logical assistance, and visual perception enhancement.
                        </figcaption>
                    </figure>
                </d-figure>
            </div>
            
            <div id="benchmark-construction" class="sub-section">
                <p class="text" align="justify">
                    <strong>Verbally-Augmented Reasoning for Visual Generation:</strong>
                    This setting evaluates whether models can use structured verbal prompts and reasoning chains to guide faithful image synthesis. It spans 4 domains (natural science, culture and art, common sense, and logic) instantiated across 7 reasoning types: temporal, spatial, causal, synthetic, quantitative, abstract, and mathematical. Each task provides a textual prompt with an initial image and a chain of constraints that a correct output image must satisfy, requiring genuine visual understanding and complex reasoning chains.
                </p>

                <p class="text" align="justify">
                    <strong>Visually-Augmented Reasoning for Verbal Generation:</strong>
                    This setting evaluates whether models can generate intermediate visualizations that strengthen their own reasoning processes. Unlike text-only Chain-of-Thought, we examine scenarios where models generate intermediate visual representations to facilitate reasoning. The benchmark focuses on 3 scenarios: physical world modeling (functioning as world simulators), logical assistance (generating visual aids for abstract problems), and visual perception enhancement (creating supportive images for challenging perception tasks).
                </p>

                <d-figure id="fig-example-outputs">
                    <figure>
                        <img data-zoomable="" draggable="false" src="static/img/example1.png" alt="Example Outputs VG" loading="lazy">
                        <figcaption>
                            <p align="justify"><strong>Figure 4: Example outputs on verbally-augmented reasoning.</strong> Each row corresponds to one reasoning subtask, with the input on the left and outputs from representative unified multimodal models shown across columns.</p>
                        </figcaption>
                    </figure>
                </d-figure>
            </div>
        </div>

        <!-- Evaluation Protocol Section -->
        <div id="evaluation-protocol" class="evaluation-protocol">
            <h1 class="text">Evaluation Protocol</h1>
            
            <p class="text" align="justify">
                <strong>Multi-Dimensional Assessment</strong>:
                Evaluating reciprocal cross-modal reasoning requires assessment of both reasoning steps and resulting outputs. Text-only metrics overlook visual fidelity, while image-only metrics cannot verify whether the image reflects valid reasoning. We adopt a multi-dimensional protocol that combines an automated VLM judge with expert validation on stratified samples.
            </p>
        
            <p class="text" align="justify">
                <strong>Verbally-Augmented Generation Metrics</strong>:
                We assess model performance across 5 rubric dimensions: (1) <strong>Reasoning Process (RP)</strong> evaluates the quality of verbal reasoning through logical structure and domain knowledge application; (2) <strong>Reasoning Visual (RV)</strong> measures how well generated visuals match target descriptions; (3) <strong>Reasoning Alignment (Align.)</strong> quantifies consistency between verbal reasoning and visual outcomes; (4) <strong>Visual Consistency (VC)</strong> ensures non-target elements remain unchanged; (5) <strong>Image Quality (IQ)</strong> assesses technical excellence and visual coherence.
            </p>
            
            <p class="text" align="justify">
                <strong>Visually-Augmented Generation Metrics</strong>:
                We evaluate across 3 dimensions: (1) <strong>Interleaved Reasoning Quality (IR)</strong> evaluates plausibility and relevance of intermediate visual representations; (2) <strong>Final Answer Accuracy (Acc.)</strong> measures whether the model's final reasoning outcome matches ground truth; (3) <strong>Reasoning-Answer Alignment (Align.)</strong> quantifies how effectively generated images contribute to reaching correct conclusions.
            </p>
            
            <d-figure id="fig-example-interleaved">
                <figure>
                    <img data-zoomable="" draggable="false" src="static/img/example2.png" alt="Example Interleaved Outputs" loading="lazy">
                    <figcaption style="text-align: center; margin-top: 20px;">
                        <strong>Figure 5: Example outputs on visually-augmented reasoning.</strong> Each row corresponds to one reasoning scenario, with the input on the left and outputs from representative unified models shown across columns.
                    </figcaption>
                </figure>
            </d-figure>
        </div>

        <!-- ROVER Leaderboard Section -->
        <div id="rover-leaderboard" class="rover-leaderboard">
            <h1 class="text"><span class="rover-logo">
  <span class="r1">R</span><span class="o">O</span><span class="v">V</span><span class="e">E</span><span class="r2">R</span>
</span> Leaderboard</h1>
            
            <div class="leaderboard-container">
                <div class="leaderboard-header">
                    <p class="text" align="justify">
                        To include your model in the leaderboard, please email <a href="mailto:charlotte9762@gmail.com">charlotte9762@gmail.com</a> with evaluation logs and setups. The scores in the leaderboard are the average of RV, IQ, and VC.
                    </p>
                </div>

                <table class="leaderboard-table">
                    <thead>
                        <tr class="header-group">
                            <th rowspan="2" data-column-index="0">Model</th>
                            <th rowspan="2" data-column-index="1">Params</th>
                            <th rowspan="2" data-column-index="2">Date</th>
                            <th rowspan="2" data-column-index="3">Nature Science</th>
                            <th rowspan="2" data-column-index="4">Culture / Art</th>
                            <th rowspan="2" data-column-index="5">Common Sense</th>
                            <th rowspan="2" data-column-index="6">Logic</th>
                            <th rowspan="2" data-column-index="7">Average</th>
                        </tr>
                    </thead>
                    <tbody id="leaderboard-body">
                        <tr>
                            <td>Nano Banana <span class="model-badge proprietary-badge">Proprietary</span></td>
                            <td>-</td>
                            <td>2025-08-22</td>
                            <td class="best-score">83.4</td>
                            <td class="best-score">81.4</td>
                            <td class="best-score">85.3</td>
                            <td class="best-score">68.8</td>
                            <td class="best-score">80.4</td>
                        </tr>
                        <tr>
                            <td>Gemini 2.0 Flash <span class="model-badge proprietary-badge">Proprietary</span></td>
                            <td>-</td>
                            <td>2025-02-05</td>
                            <td>74.0</td>
                            <td>73.5</td>
                            <td>77.9</td>
                            <td>63.3</td>
                            <td>72.2</td>
                        </tr>
                        <tr>
                            <td>GPT-5 <span class="model-badge proprietary-badge">Proprietary</span></td>
                            <td>-</td>
                            <td>2025-08-07</td>
                            <td>77.3</td>
                            <td>75.9</td>
                            <td>77.8</td>
                            <td>69.2</td>
                            <td>74.9</td>
                        </tr>
                        <tr>
                            <td>BAGEL-Think14B <span class="model-badge open-badge">Open Source</span></td>
                            <td>14B</td>
                            <td>2025-05-23</td>
                            <td>65.9</td>
                            <td>67.1</td>
                            <td>71.1</td>
                            <td>48.7</td>
                            <td>65.2</td>
                        </tr>
                        <tr>
                            <td>BAGEL14B <span class="model-badge open-badge">Open Source</span></td>
                            <td>14B</td>
                            <td>2025-05-23</td>
                            <td>53.2</td>
                            <td>57.2</td>
                            <td>58.1</td>
                            <td>55.4</td>
                            <td>56.1</td>
                        </tr>
                        <tr>
                            <td>Step1X-Edit v1.2 <span class="model-badge open-badge">Open Source</span></td>
                            <td>-</td>
                            <td>2025-09-08</td>
                            <td>67.9</td>
                            <td>64.3</td>
                            <td>64.3</td>
                            <td>50.6</td>
                            <td>63.2</td>
                        </tr>
                        <tr>
                            <td>UniCoT14B <span class="model-badge open-badge">Open Source</span></td>
                            <td>14B</td>
                            <td>2025-07-29</td>
                            <td>56.3</td>
                            <td>73.1</td>
                            <td>68.5</td>
                            <td>32.7</td>
                            <td>58.5</td>
                        </tr>
                        <tr>
                            <td>BLIP3o-8B <span class="model-badge open-badge">Open Source</span></td>
                            <td>8B</td>
                            <td>2025-05-23</td>
                            <td>67.9</td>
                            <td>66.1</td>
                            <td>66.6</td>
                            <td>58.0</td>
                            <td>64.6</td>
                        </tr>
                        <tr>
                            <td>MetaQuery-XL <span class="model-badge open-badge">Open Source</span></td>
                            <td>8.6B</td>
                            <td>2025-04-28</td>
                            <td>-</td>
                            <td>-</td>
                            <td>-</td>
                            <td>-</td>
                            <td>-</td>
                        </tr>
                        <tr>
                            <td>Janus-Pro-7B <span class="model-badge open-badge">Open Source</span></td>
                            <td>7B</td>
                            <td>2025-01-27</td>
                            <td>-</td>
                            <td>-</td>
                            <td>-</td>
                            <td>-</td>
                            <td>-</td>
                        </tr>
                        <tr>
                            <td>Emu3-Gen <span class="model-badge open-badge">Open Source</span></td>
                            <td>8B</td>
                            <td>2025-02-13</td>
                            <td>52.2</td>
                            <td>57.5</td>
                            <td>52.5</td>
                            <td>54.7</td>
                            <td>54.0</td>
                        </tr>
                        <tr>
                            <td>OmniGen <span class="model-badge open-badge">Open Source</span></td>
                            <td>27B</td>
                            <td>2025-06-16</td>
                            <td>58.2</td>
                            <td>62.5</td>
                            <td>61.3</td>
                            <td>45.6</td>
                            <td>56.8</td>
                        </tr>
                        <tr>
                            <td>Show-o <span class="model-badge open-badge">Open Source</span></td>
                            <td>27B</td>
                            <td>2025-06-18</td>
                            <td>-</td>
                            <td>-</td>
                            <td>-</td>
                            <td>-</td>
                            <td>-</td>
                        </tr>
                        <tr>
                            <td>Qwen-Image-Edit <span class="model-badge edit-badge">Edit</span></td>
                            <td>20B</td>
                            <td>2025-08-04</td>
                            <td>68.6</td>
                            <td>75.8</td>
                            <td>74.0</td>
                            <td>60.7</td>
                            <td>71.2</td>
                        </tr>
                        <tr>
                            <td>FLUX.1 Kontext <span class="model-badge edit-badge">Edit</span></td>
                            <td>12B</td>
                            <td>2025-08-06</td>
                            <td>60.9</td>
                            <td>66.1</td>
                            <td>63.1</td>
                            <td>49.7</td>
                            <td>61.5</td>
                        </tr>
                        <tr>
                            <td>UltraEdit(SD3) <span class="model-badge edit-badge">Edit</span></td>
                            <td>2B</td>
                            <td>2024-08-31</td>
                            <td>48.8</td>
                            <td>55.6</td>
                            <td>46.7</td>
                            <td>53.8</td>
                            <td>51.1</td>
                        </tr>
                        <tr>
                            <td>VAREdit-8B <span class="model-badge edit-badge">Edit</span></td>
                            <td>8B</td>
                            <td>2025-08-21</td>
                            <td>58.2</td>
                            <td>61.1</td>
                            <td>55.9</td>
                            <td>40.4</td>
                            <td>55.8</td>
                        </tr>
                        <tr>
                            <td>Step1X-Edit v1.1 <span class="model-badge edit-badge">Edit</span></td>
                            <td>-</td>
                            <td>2025-06-09</td>
                            <td>66.5</td>
                            <td>65.7</td>
                            <td>62.8</td>
                            <td>54.4</td>
                            <td>63.5</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <!-- Main Results Section -->
        <div id='experimental-results' class="experimental-results">
            <h1 class="text">Main Results</h1>
                
            <p class="text" align="justify">
                We conducted comprehensive evaluation of 17 state-of-the-art unified multimodal models across both settings in <span class="rover-logo">
  <span class="r1">R</span><span class="o">O</span><span class="v">V</span><span class="e">E</span><span class="r2">R</span>
</span>. Our experiments reveal critical insights about the current state and limitations of cross-modal reasoning capabilities in modern UMMs.
            </p>

            <p class="text" align="justify">
                <strong>Verbally-Augmented Visual Generation Results</strong>:
                Cross-modal reasoning capabilities and alignment strongly correlate with visual generation effectiveness. Closed-source models excel in reasoning processes and demonstrate strong alignment performance, directly contributing to superior visual generation quality. Open-source models show notably weaker verbal reasoning during visual generation tasks‚Äîtheir reasoning processes are approximately 38% lower and alignment performance falls about 31% short of closed-source models, translating into correspondingly diminished visual generation performance.
            </p>

            <p class="text" align="justify">
                <strong>Visually-Augmented Verbal Generation Results</strong>:
                Current unified models exhibit limited capacity in interleaved reasoning, constraining their ability to leverage cross-modal reasoning for improved performance. Even the best-performing models struggle with interleaved reasoning processes, with the highest average Interleaved Reasoning (IR) score reaching only 39.5% overall. Models demonstrate superior performance on physical world modeling and visual perception tasks compared to logical reasoning challenges, indicating that perception over pixels transfers more readily than acquisition of abstract visual concepts.
            </p>

            <div class="highlight-box">
                <em>Key Finding 1: Cross-modal reasoning capabilities strongly correlate with visual generation performance, particularly for interleaved image-text generation.</em>
            </div>

            <div class="highlight-box">
                <em>Key Finding 2: Current models remain severely limited in visually-augmented reasoning, showing relative strength in perception and physical modeling but weakness in logical tasks.</em>
            </div>
        </div>

        <!-- Analysis and Insights Section -->
        <div id='analysis-insights' class="analysis-insights">
            <h1 class="text">Analysis and Insights</h1>
            
            <p class="text" align="justify">
                <strong>Cross-Modal Reasoning Matters for UMMs</strong>:
                To validate that UMMs perform cross-modal reasoning internally and that this mechanism cannot be replicated through external models, we conducted comparative analysis between unified models and cascade approaches. Results demonstrate that reasoning across modalities cannot fully transfer across different model architectures‚Äîunified models must transcend modality boundaries to produce emergent cross-modal insights.
            </p>

            <d-figure id="fig-cascade-analysis">
                <figure>
                    <img data-zoomable="" draggable="false" src="static/img/cascade.png" alt="Cascade Analysis" loading="lazy">
                    <figcaption style="text-align: center; margin-top: 20px;">
                        <strong>Figure 6</strong>: Cascade reasoning evaluation comparing cascade approaches (FLUX+GPT with GPT-4o prompt refinement) against unified multimodal models.
                    </figcaption>
                </figure>
            </d-figure>
            
            <p class="text" align="justify">
                <strong>Coherence Between Reasoning Subtasks</strong>:
                Analysis reveals uneven performance across reasoning dimensions, with models excelling in temporal, spatial, and causal reasoning while struggling with abstract and mathematical tasks. This pattern indicates that current UMMs better handle concrete, observable phenomena than symbolic reasoning. Strong interdependence among physical reasoning types suggests shared mechanisms for processing spatiotemporal relationships, while abstract reasoning develops as a distinct capability.
            </p>
            
            <d-figure id="fig-reasoning-analysis">
                <figure>
                    <img data-zoomable="" draggable="false" src="static/img/reasoning.png" alt="Reasoning Analysis" loading="lazy">
                    <figcaption style="text-align: center; margin-top: 20px;">
                        <strong>Figure 7</strong>: Analysis of reasoning capabilities showing performance patterns across different reasoning subtasks and their correlations.
                    </figcaption>
                </figure>
            </d-figure>

            <p class="text" align="justify">
                <strong>Evaluation Protocol Reliability</strong>:
                We conducted user studies with 4 human experts to validate our VLM-as-judge evaluation protocol. Results demonstrate strong alignment between GPT-4.1 and human expert judgments across all evaluation dimensions. Visual-quality-related metrics show particularly strong human-VLM agreement, while reasoning-related metrics exhibit larger but acceptable discrepancies due to inherent complexities in multimodal reasoning assessment.
            </p>
            
            <d-figure id="fig-evaluation-reliability">
                <figure>
                    <img data-zoomable="" draggable="false" src="static/img/vlm_evaluation_metrics.png" alt="Evaluation Reliability" loading="lazy">
                    <figcaption style="text-align: center; margin-top: 20px;">
                        <strong>Figure 8</strong>: Evaluation reliability of GPT-4.1 across five assessment dimensions, showing Pearson correlation coefficients and Mean Absolute Error compared to human experts.
                    </figcaption>
                </figure>
            </d-figure>
        </div>

        <!-- Conclusion Section -->
        <div id="conclusion" style="position: relative; margin-top: 40px; margin-bottom: 0px;">
            <h2 class="text" style="margin-top:0px; margin-bottom:10px">Conclusion</h2>
            <p class="text" align="justify">
                We introduce <span class="rover-logo">
  <span class="r1">R</span><span class="o">O</span><span class="v">V</span><span class="e">E</span><span class="r2">R</span>
</span>, the first benchmark for reciprocal cross-modal reasoning, which systematically evaluates 17 unified multimodal models across 23 diverse task types in both verbal reasoning for visual generation and interleaved multimodal reasoning scenarios. Our evaluation exposes substantial performance gaps in current models and establishes that interleaved generation capabilities are strongly correlated with cross-modal reasoning effectiveness. These findings expose critical limitations in existing unified models and provide insights for advancing cross-modal reasoning capabilities in future omnimodal models. <span class="rover-logo">
  <span class="r1">R</span><span class="o">O</span><span class="v">V</span><span class="e">E</span><span class="r2">R</span>
</span> represents a critical step toward enabling true omnimodal generation through reciprocal cross-modal reasoning.
            </p>
        </div>

        <!-- BibTeX Section -->
        <div id="bibtex" style="position: relative; margin-top: 40px; margin-bottom: 0px; color: gray;">
            <h2 class="text" style="margin-top:0px; margin-bottom:10px">BibTeX</h2>
            <pre><code>@article{yang2024think,
    title={{Thinking in Space: How Multimodal Large Language Models See, Remember and Recall Spaces}},
    author={Yang, Jihan and Yang, Shusheng and Gupta, Anjali W. and Han, Rilyn and Fei-Fei, Li and Xie, Saining},
    year={2024},
    journal={arXiv preprint arXiv:2412.14171},
}</code></pre>
        </div>
    </d-article>

    <!-- Non-critical scripts loaded asynchronously -->
    <script>
        // Load scripts asynchronously after page load
        function loadScript(src, callback) {
            const script = document.createElement('script');
            script.src = src;
            script.async = true;
            if (callback) script.onload = callback;
            document.head.appendChild(script);
        }

        window.addEventListener('load', function() {
            // Load non-critical scripts
            loadScript('./static/js/distill_template.v2.js');
            loadScript('https://polyfill.io/v3/polyfill.min.js?features=es6');
            loadScript('https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js');
            loadScript('https://d3js.org/d3.v5.min.js');
            loadScript('https://d3js.org/d3-collection.v1.min.js');
            loadScript('https://rawgit.com/nstrayer/slid3r/master/dist/slid3r.js');
            loadScript('./static/js/hider.js');
            loadScript('./static/js/image_interact.js');
            loadScript('./static/js/switch_videos.js');
            loadScript('./static/js/video-speed.js');
            loadScript('./static/js/fontawesome.all.min.js');
            loadScript('https://cdn.jsdelivr.net/npm/jquery@3.7.1/dist/jquery.min.js');
            loadScript('./static/js/medium-zoom.min.js');
            loadScript('./static/js/zoom.js');
            loadScript('https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js', function() {
                loadScript('https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js', function() {
                    renderMathInElement(document.body);
                });
            });
        });
    </script>

    <!-- Leaderboard Sorting JavaScript -->
    <script>
    document.addEventListener('DOMContentLoaded', function () {
        const table = document.querySelector('.leaderboard-table');
        if (!table) return;
        
        const thead = table.querySelector('thead');
        const tbody = document.getElementById('leaderboard-body');
        
        let sortConfig = {
            columnIndex: 7, 
            direction: 'desc'
        };

        const headers = thead.querySelectorAll('th[data-column-index]');

        function updateSortIndicators() {
            headers.forEach(h => {
                const indicator = h.querySelector('.sort-indicator');
                if (indicator) {
                    const hIndex = parseInt(h.dataset.columnIndex);
                    if (hIndex === sortConfig.columnIndex) {
                        indicator.textContent = sortConfig.direction === 'asc' ? '‚ñ≤' : '‚ñº';
                        h.classList.add('active');
                    } else {
                        indicator.textContent = '';
                        h.classList.remove('active');
                    }
                }
            });
        }
        
        function parseParams(param) {
            if (param === '-') return -1;
            const value = parseFloat(param);
            if (isNaN(value)) return -1;
            if (param.toLowerCase().includes('b')) return value * 1e9;
            if (param.toLowerCase().includes('m')) return value * 1e6;
            return value;
        }

        function compareValues(valA, valB, index) {
            if (index === 0) { 
                return valA.localeCompare(valB);
            }
            if (index === 1) { 
                return parseParams(valA) - parseParams(valB);
            }
            if (index === 3) { 
                return new Date(valA) - new Date(valB);
            }

            const numA = parseFloat(valA);
            const numB = parseFloat(valB);
            const isNumA = !isNaN(numA);
            const isNumB = !isNaN(numB);

            if (isNumA && isNumB) return numA - numB;
            if (isNumA) return 1;
            if (isNumB) return -1;
            return 0;
        }

        function sortTable() {
            const rows = Array.from(tbody.querySelectorAll('tr'));
            
            const sortableRows = rows.filter(row => 
                !row.classList.contains('baseline-row') &&
                !row.classList.contains('human-level-row') &&
                !row.classList.contains('section-divider') &&
                !row.classList.contains('section-header')
            );
            
            const direction = sortConfig.direction === 'asc' ? 1 : -1;

            sortableRows.sort((rowA, rowB) => {
                const cellA = rowA.children[sortConfig.columnIndex].textContent.trim();
                const cellB = rowB.children[sortConfig.columnIndex].textContent.trim();
                return compareValues(cellA, cellB, sortConfig.columnIndex) * direction;
            });

            sortableRows.forEach(row => tbody.appendChild(row));
            updateSortIndicators();
        }

        headers.forEach(header => {
            header.classList.add('sortable-header');
            const indicator = document.createElement('span');
            indicator.className = 'sort-indicator';
            header.appendChild(indicator);

            header.addEventListener('click', () => {
                const columnIndex = parseInt(header.dataset.columnIndex);
                if (sortConfig.columnIndex === columnIndex) {
                    sortConfig.direction = sortConfig.direction === 'asc' ? 'desc' : 'asc';
                } else {
                    sortConfig.columnIndex = columnIndex;
                    sortConfig.direction = 'desc';
                }
                sortTable();
            });
        });

        sortTable();
    });
    </script>
</body>
</html>